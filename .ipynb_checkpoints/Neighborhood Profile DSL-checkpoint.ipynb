{
 "metadata": {
  "name": "",
  "signature": "sha256:e6199dac0ad5b94ebba35a40a3f840e69c479b07193a2f54e4a4e47f7d432671"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dependencies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd, numpy as np, census, us, csv, os, math\n",
      "import requests, json\n",
      "import urllib2\n",
      "import re\n",
      "from scipy.stats import norm # needed for percent point function norm.ppf (used in significance testing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Global Variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "apikey = \"827a8aafba255606ced9b44cd4380ba61ad39003\" # Drew's API key, stay cool bros"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elmhurst = [\"06001409300\", \"06001409400\", \"06001409500\", \"06001409600\", \"06001409700\", \"06001410200\", \"06001410300\", \"06001410400\"]\n",
      "oakland = [\"0653000\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Helper Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Returns a list of lists no longer than n (used to deal with Census API limit of 50 variables per call)\n",
      "\n",
      "def chunks(l, n): \n",
      "    if n < 1:\n",
      "        n = 1\n",
      "    return [l[i:i + n] for i in range(0, len(l), n)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Stitches together multiple dataframes. Moves state, county, tract to first three columns and drops them from subsequent dfs\n",
      "\n",
      "def concatenate_dataframes(geo_type, *dfs):\n",
      "    if geo_type == \"tract\":\n",
      "        masterframe = dfs[0].iloc[:,:-3]\n",
      "    elif geo_type == \"place\":\n",
      "        masterframe = dfs[0].iloc[:,:-2]\n",
      "\n",
      "    if len(dfs) > 1:\n",
      "        for df in dfs[1:]:\n",
      "            masterframe = pd.concat([masterframe, df.iloc[:,:-3 if geo_type == \"tract\" else -2]], axis = 1) #axis=\"1\"= concat across col instead of across rows\n",
      "            \n",
      "    return masterframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def se_rename(text):\n",
      "    \"\"\"Replaces \"Margin of Error\" with \"Standard Error\" in column names\"\"\"\n",
      "    try:\n",
      "        strings = re.search('(^.+ )Margin Of Error(.+$)', text)\n",
      "    except AttributeError:\n",
      "        strings = '' # apply your error handling\n",
      "\n",
      "    return strings.group(1) + \"Standard Error\" + strings.group(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Homemade Census API calling, more flexible than the census package permits\n",
      "# HUGE thanks to Aksel Olsen (via Sam Blanchard) for this function\n",
      "\n",
      "def get_data(year,dataset,table,geo_type):\n",
      "    \"\"\"\n",
      "    Gets data from api based on year, dataset and tablename\n",
      "    \"\"\"\n",
      "    \n",
      "    #concatenate table list to pass to url param\n",
      "    stable = ','.join(table)\n",
      "    \n",
      "    url = 'http://api.census.gov/data/%(yr)s/%(dset)s?key=%(key)s&get=%(tbl)s&for=%(type)s:*&in=state:06'\n",
      "    url = url %{\n",
      "    'key':apikey,\n",
      "    'yr':year,\n",
      "    'dset':dataset,\n",
      "    'tbl':stable,\n",
      "    'type': geo_type\n",
      "    }\n",
      "#    print url\n",
      "    ## get data\n",
      "    resp = requests.get(url)\n",
      "        \n",
      "    try:\n",
      "        data = pd.read_json(resp.text)\n",
      "        \n",
      "        ## col names are found at index 0\n",
      "        cols = data.ix[0,].tolist()\n",
      "           \n",
      "        data.columns=cols\n",
      "                        \n",
      "        ## data ships with empty row--remove, or else it won't work (DSL 10/12/2014)\n",
      "        data=data.drop(data.index[:1])\n",
      "        \n",
      "        if year == \"2000\": # Dealing with the lack of leading zeros in 2000 FIPS codes cost me well over an hour. :(\n",
      "            data[\"state\"] = data[\"state\"].apply(\"{:0>2}\".format)\n",
      "            if geo_type == \"tract\":\n",
      "                data[\"county\"] = data[\"county\"].apply(\"{:0>3}\".format)\n",
      "                data[\"tract\"] = data[\"tract\"].apply(\"{:0>6}\".format)\n",
      "            else:\n",
      "                data[\"place\"] = data[\"place\"].apply(\"{:0>5}\".format)\n",
      "\n",
      "        # Leaving in all this debris from my long struggle with this problem. FYI the correct answer is here: http://stackoverflow.com/questions/23836277/add-leading-zeros-to-strings-in-pandas-dataframe\n",
      "#        print data.head()\n",
      "#        if year == \"2000\":\n",
      "#            data.state = data.state.astype(str)\n",
      "#            total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)\n",
      "#            data[\"state\"] = str(data[\"state\"]).zfill(2)\n",
      "#        print data.head()\n",
      "        ## add unique geoid as index - using ternary operator to select correct geoid format AND using zfill to ensure proper formatting of 2000 data (which normally lack leading zeros)\n",
      "        data.index = data.state + data.county + data.tract if geo_type == \"tract\" else data.state + data.place\n",
      "#        data.index = \"%02d%03d%06d\" % (data.state, data.county, data.tract) if geo_type == \"tract\" else \"%02d%05d\" % (data.state, data.place)\n",
      "#        data.index = \"%02s%03s%06s\" % (data.state, data.county, data.tract) if geo_type == \"tract\" else \"%02s%05s\" % (data.state, data.place)\n",
      "#        data.index = str(data.state).zfill(2)+str(data.county).zfill(3)+str(data.tract).zfill(6) if geo_type == \"tract\" else str(data.state).zfill(2)+str(data.place).zfill(5)\n",
      "                \n",
      "        ## make sure numeric data is numeric\n",
      "        data.ix[:,table]=data[table].astype('float64')\n",
      "        \n",
      "        return data\n",
      "    except Exception, e:\n",
      "        raise    # decoding failed\n",
      "        print \"holy smokes!\"\n",
      "        print \"failed on %s\" %url\n",
      "    else:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Takes an arbitrarily long list of variables, a year and dataset (e.g. \"sf1\", \"acs5\"), makes multiple API calls and stitches it all together\n",
      "\n",
      "def census_api_pull(vars_list, year, dataset, geo_type):\n",
      "    ## get variable details, labels\n",
      "    jsonurl = 'http://api.census.gov/data/%(yr)s/%(dset)s/variables.json' % {'yr': year, 'dset': dataset}\n",
      "    jsontext = requests.get(jsonurl)\n",
      "\n",
      "    ## rename columns, looking up in dictionary. Perhaps bad form w verbose names\n",
      "    datadict = pd.DataFrame(jsontext.json()['variables']).T\n",
      "        \n",
      "    ## get labels, stuff in dict\n",
      "    datadict_rename = datadict.ix[vars_list,'label'].to_dict()\n",
      "    datadict_rename_verbose = dict(zip(datadict_rename.keys(), [key + \" \" + value for key, value in datadict_rename.items()]))\n",
      "        \n",
      "    var_chunks = chunks(vars_list, 50) # split up the LIST into chunks of 50 variables\n",
      "    results_list = []\n",
      "    \n",
      "    for var_chunk in var_chunks:\n",
      "        df = get_data(year, dataset, var_chunk, geo_type) # perform census api pull (using Aksel's code)\n",
      "        results_list.append(df) #append the df to results_list\n",
      "        \n",
      "    masterframe = concatenate_dataframes(geo_type, *results_list) #I think the splat is needed here\n",
      "\n",
      "    ## rename: new name has both official variable name and legible description\n",
      "    masterframe.rename(columns=datadict_rename_verbose,inplace=True)\n",
      "    \n",
      "    fname = \"census_%s_%s_%s.csv\" % (dataset, year, geo_type)\n",
      "    print \"writing data to %s\" %fname\n",
      "    masterframe.to_csv(fname)\n",
      "    \n",
      "    return masterframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 231
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysis Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Returns True if the difference between x and y, given x_se and y_se, is statistically significant at the given confidence interval\n",
      "\n",
      "def significant(x, x_se, y, y_se, ci): #\n",
      "    p = ci + (1 - ci)/2 # convert confidence interval into two-tailed test critical value\n",
      "    z = norm.ppf(p) # z-score\n",
      "    return abs((x - y)/(x_se**2 + y_se**2)**0.5) > z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def moe_to_se(df):\n",
      "    \"\"\"Converts all Margin Of Error columns into Standard Error (by dividing by 1.645), and renames columns accordingly\"\"\"\n",
      "    colnames = []\n",
      "    new = df.copy()\n",
      "    \n",
      "    for colname in new.columns:\n",
      "        if \"Margin Of Error\" in colname:\n",
      "            new[colname] = new[colname] / 1.645\n",
      "            colnames.append(se_rename(colname))\n",
      "        else:\n",
      "            colnames.append(colname)\n",
      "    \n",
      "    new.columns = colnames\n",
      "    \n",
      "    return new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculates MOE for a proportion (use after aggregating estimates and MOEs across multiple tracts)\n",
      "\n",
      "def moe_proportion(num, num_moe, den, den_moe):\n",
      "    p = float(num) / den\n",
      "\n",
      "    if num_moe**2 - (p**2 * den_moe**2) >= 0:\n",
      "        return (num_moe**2 - (p**2 * den_moe**2))**0.5 / den\n",
      "    else:\n",
      "        return (num_moe**2 + (p**2 * den_moe**2))**0.5 / den"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Aggregate census tracts for tables with counts\n",
      "\n",
      "def agg(df):\n",
      "    new = df.copy()\n",
      "    new.loc['Aggregate'] = 0\n",
      "    for i in new.columns:\n",
      "        if \"Margin Of Error\" in i:\n",
      "            new.loc[\"Aggregate\", i] = (sum(new[i]**2))**.5\n",
      "        else:\n",
      "            new.loc[\"Aggregate\", i] = sum(new[i])\n",
      "    return new.loc[\"Aggregate\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 235
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Test Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sam's variable lists\n",
      "\n",
      "#UNWEIGHTED SAMPLE COUNT OF THE POPULATION\n",
      "totpopE = ['B01003_001E']\n",
      "totpopM = ['B01003_001M']\n",
      "#UNWEIGHTED SAMPLE HOUSING UNITS\n",
      "tothouseunitsE = ['B25001_001E']\n",
      "tothouseunitsM = ['B25001_001M']\n",
      "#SEX BY AGE\n",
      "ageE  =['B01001_0%02dE'%i for i in range(1,50)]\n",
      "ageM  =['B01001_0%02dM'%i for i in range(1,50)]\n",
      "#RACE\n",
      "raceE  =['B02001_0%02dE'%i for i in range(1,11)]\n",
      "raceM  =['B02001_0%02dM'%i for i in range(1,11)]\n",
      "#HISPANIC OR LATINO ORIGIN BY RACE\n",
      "racehispE = ['B03002_0%02dE'%i for i in range(1,4)]\n",
      "racehispM = ['B03002_0%02dM'%i for i in range(1,4)]\n",
      "#POVERTY STATUS IN THE PAST 12 MONTHS BY SEX BY AGE\n",
      "povertyE = ['B17001_0%02dE'%i for i in range(1,22)]\n",
      "povertyM = ['B17001_0%02dM'%i for i in range(1,22)]\n",
      "#HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2010 INFLATION-ADJUSTED DOLLARS)\n",
      "incomeE = ['B19001_0%02dE'%i for i in range(1,18)]\n",
      "incomeM = ['B19001_0%02dM'%i for i in range(1,18)]\n",
      "#SEX BY EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER\n",
      "educationE = ['B15002_0%02dE'%i for i in range(1,36)]\n",
      "educationM = ['B15002_0%02dM'%i for i in range(1,36)]\n",
      "#TENURE BY HOUSEHOLD TYPE AND PRESENCE AND AGE OF OWN CHILDREN\n",
      "tenureE = ['B25003_0%02dE'%i for i in range(1,4)]\n",
      "tenureM = ['B25003_0%02dM'%i for i in range(1,4)]\n",
      "#TENURE BY VEHICLES AVAILABLE\n",
      "vehicleE = ['B25044_0%02dE'%i for i in range(1,16)]\n",
      "vehicleM = ['B25044_0%02dM'%i for i in range(1,16)]\n",
      "#TRAVEL TIME TO WORK FOR WORKPLACE GEOGRAPHY\n",
      "commutetimeE = ['B08603_0%02dE'%i for i in range(1,14)]\n",
      "commutetimeM = ['B08603_0%02dM'%i for i in range(1,14)]\n",
      "#MEANS OF TRANSPORTATION TO WORK\n",
      "commutemodeE = ['B08301_0%02dE'%i for i in range(1,22)]\n",
      "commutemodeM = ['B08301_0%02dM'%i for i in range(1,22)]\n",
      "\n",
      "#set \"variables\" as a list of all variables specified above\n",
      "#break into 50 var calls - make a loop that loops through each above list then pulls data then aggregates all dataframes into one.\n",
      "variables_all = totpopE + totpopM + tothouseunitsE + tothouseunitsM + ageE + ageM + raceE + raceM + racehispE + racehispM + povertyE + povertyM + incomeE + incomeM + educationE + educationM + tenureE + tenureM + vehicleE + vehicleM + commutetimeE + commutetimeM + commutemodeE + commutemodeM\n",
      "#print (variables_all)\n",
      "variables1 = totpopE + totpopM + tothouseunitsE + tothouseunitsM\n",
      "variables2 = ageE\n",
      "variables3 = ageM\n",
      "variables4 = raceE + raceM + racehispE + racehispM\n",
      "variables5 = povertyE + povertyM\n",
      "variables6 = incomeE + incomeM\n",
      "variables7 = educationE\n",
      "variables8 = educationM\n",
      "variables9 = tenureE + tenureM + vehicleE + vehicleM\n",
      "variables10 = commutetimeE + commutetimeM\n",
      "variables11 = commutemodeE + commutemodeM\n",
      "\n",
      "#2000 SF1\n",
      "#Total Population\n",
      "totpop_sf1_00 = ['P001001']\n",
      "#Total Housing units\n",
      "tothouseunits_sf1_00 = ['H001001']\n",
      "\n",
      "#2000 SF3\n",
      "#Total Population\n",
      "totpop_sf3_00 = ['P001001']\n",
      "#Total Housing units\n",
      "tothouseunits_sf3_00 = ['H001001']\n",
      "#SEX BY AGE\n",
      "age1_sf3_00 =['P0080%02d'%i for i in range(1,50)]\n",
      "age2_sf3_00 =['P0080%02d'%i for i in range(50,80)]\n",
      "#RACE\n",
      "race_sf3_00 =['P0060%02d'%i for i in range(1,9)]\n",
      "#Hispanic or Latino by Race\n",
      "racehisp_sf3_00 =['P0070%02d'%i for i in range(1,18)]\n",
      "#Poverty Status in 1999 by Sex by Age\n",
      "poverty1_sf3_00 =['PCT0490%02d'%i for i in range(1,50)]\n",
      "poverty2_sf3_00 =['PCT0490%02d'%i for i in range(50,60)]\n",
      "#Household Income in 1999\n",
      "income_sf3_00 =['P0520%02d'%i for i in range(1,18)]\n",
      "#SEX BY EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER\n",
      "education_sf3_00 =['P0370%02d'%i for i in range(1,36)]\n",
      "#Tenure\n",
      "tenure_sf3_00 =['H0070%02d'%i for i in range(1,4)]\n",
      "#Aggregate Number of Vehicles Available by Tenure\n",
      "vehicle_sf3_00 =['H0460%02d'%i for i in range(1,4)]\n",
      "#Travel Time to Work for Workers 16 Years and Over\n",
      "commutetime_sf3_00 =['P0310%02d'%i for i in range(1,16)]\n",
      "#Means of Transportation to Work for Workers 16 Years and Over\n",
      "commutemode_sf3_00 =['P0300%02d'%i for i in range(1,17)]\n",
      "\n",
      "#2010 sf1\n",
      "#Total Population\n",
      "totpop_sf1_10 = ['P0010001']\n",
      "#Total Housing units\n",
      "tothouseunits_sf1_10 = ['H00010001']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tractData = census_api_pull(ageE + ageM, \"2012\", \"acs5\", \"tract\")\n",
      "placeData = census_api_pull(ageE + ageM, \"2012\", \"acs5\", \"place\")\n",
      "concatData = tractData.append(placeData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing data to census_acs5_2012_tract.csv\n",
        "writing data to census_acs5_2012_place.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elmhurstData = concatData[concatData.index.isin(elmhurst)]\n",
      "oaklandData = concatData[concatData.index.isin(oakland)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moe_proportion(10,2,20,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 239,
       "text": [
        "0.08660254037844387"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moe_proportion(10,2/1.645,20,2/1.645)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 240,
       "text": [
        "0.05264592120270143"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "0.05/1.645"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 241,
       "text": [
        "0.030395136778115502"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "0.08660254037844387 / 1.645"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 242,
       "text": [
        "0.05264592120270144"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aggregate = agg(elmhurstData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elmhurstData.to_csv(\"elmhurstData.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print aggregate.filter(regex = \"B01001_002E\").values\n",
      "print aggregate.filter(regex = \"B01001_002M\").values\n",
      "print aggregate.filter(regex = \"B01001_001E\").values\n",
      "print aggregate.filter(regex = \"B01001_001M\")[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[17915.0]\n",
        "[1011.5962633382944]\n",
        "[36810.0]\n",
        "1752.30105861\n"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moe_proportion(aggregate.filter(regex = \"B01001_002E\")[0], aggregate.filter(regex = \"B01001_002M\")[0], aggregate.filter(regex = \"B01001_001E\")[0], aggregate.filter(regex = \"B01001_001M\")[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 249,
       "text": [
        "0.014780620248178661"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print moe_proportion(17915, 1011.596, 36810, 1752.301)\n",
      "print moe_proportion(17915, 1011.596/1.645, 36810, 1752.301/1.645)\n",
      "print moe_proportion(17915, 1011.596, 36810, 1752.301)/1.645"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0147806081614\n",
        "0.0089851721346\n",
        "0.0089851721346\n"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elmhurstSE = moe_to_se(elmhurstData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elmhurstSE.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>B01001_001E Total:</th>\n",
        "      <th>B01001_002E Male:</th>\n",
        "      <th>B01001_003E Male:!!Under 5 years</th>\n",
        "      <th>B01001_004E Male:!!5 to 9 years</th>\n",
        "      <th>B01001_005E Male:!!10 to 14 years</th>\n",
        "      <th>B01001_006E Male:!!15 to 17 years</th>\n",
        "      <th>B01001_007E Male:!!18 and 19 years</th>\n",
        "      <th>B01001_008E Male:!!20 years</th>\n",
        "      <th>B01001_009E Male:!!21 years</th>\n",
        "      <th>B01001_010E Male:!!22 to 24 years</th>\n",
        "      <th>...</th>\n",
        "      <th>B01001_040M Standard Error For!!Female:!!50 to 54 years</th>\n",
        "      <th>B01001_041M Standard Error For!!Female:!!55 to 59 years</th>\n",
        "      <th>B01001_042M Standard Error For!!Female:!!60 and 61 years</th>\n",
        "      <th>B01001_043M Standard Error For!!Female:!!62 to 64 years</th>\n",
        "      <th>B01001_044M Standard Error For!!Female:!!65 and 66 years</th>\n",
        "      <th>B01001_045M Standard Error For!!Female:!!67 to 69 years</th>\n",
        "      <th>B01001_046M Standard Error For!!Female:!!70 to 74 years</th>\n",
        "      <th>B01001_047M Standard Error For!!Female:!!75 to 79 years</th>\n",
        "      <th>B01001_048M Standard Error For!!Female:!!80 to 84 years</th>\n",
        "      <th>B01001_049M Standard Error For!!Female:!!85 years and over</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>06001409300</th>\n",
        "      <td> 5641</td>\n",
        "      <td> 2602</td>\n",
        "      <td> 293</td>\n",
        "      <td> 105</td>\n",
        "      <td> 312</td>\n",
        "      <td> 139</td>\n",
        "      <td> 87</td>\n",
        "      <td> 52</td>\n",
        "      <td> 51</td>\n",
        "      <td>  87</td>\n",
        "      <td>...</td>\n",
        "      <td> 54.10334</td>\n",
        "      <td> 49.84802</td>\n",
        "      <td>  21.2766</td>\n",
        "      <td> 39.51368</td>\n",
        "      <td> 15.19757</td>\n",
        "      <td> 51.06383</td>\n",
        "      <td> 54.10334</td>\n",
        "      <td> 35.86626</td>\n",
        "      <td> 25.53191</td>\n",
        "      <td> 30.39514</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>06001409400</th>\n",
        "      <td> 4661</td>\n",
        "      <td> 2405</td>\n",
        "      <td> 340</td>\n",
        "      <td> 281</td>\n",
        "      <td>  90</td>\n",
        "      <td>  63</td>\n",
        "      <td> 90</td>\n",
        "      <td>  2</td>\n",
        "      <td> 54</td>\n",
        "      <td> 277</td>\n",
        "      <td>...</td>\n",
        "      <td> 33.43465</td>\n",
        "      <td> 33.43465</td>\n",
        "      <td> 25.53191</td>\n",
        "      <td> 5.471125</td>\n",
        "      <td> 18.23708</td>\n",
        "      <td> 13.98176</td>\n",
        "      <td> 9.118541</td>\n",
        "      <td> 24.31611</td>\n",
        "      <td> 7.902736</td>\n",
        "      <td> 15.80547</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>06001409500</th>\n",
        "      <td> 4061</td>\n",
        "      <td> 2034</td>\n",
        "      <td> 261</td>\n",
        "      <td> 156</td>\n",
        "      <td>  90</td>\n",
        "      <td>  99</td>\n",
        "      <td> 63</td>\n",
        "      <td> 66</td>\n",
        "      <td> 59</td>\n",
        "      <td>  87</td>\n",
        "      <td>...</td>\n",
        "      <td> 23.70821</td>\n",
        "      <td> 29.78723</td>\n",
        "      <td> 24.31611</td>\n",
        "      <td> 27.96353</td>\n",
        "      <td>  23.1003</td>\n",
        "      <td> 26.74772</td>\n",
        "      <td> 7.902736</td>\n",
        "      <td> 9.726444</td>\n",
        "      <td> 4.863222</td>\n",
        "      <td> 16.41337</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>06001409600</th>\n",
        "      <td> 5602</td>\n",
        "      <td> 2811</td>\n",
        "      <td> 468</td>\n",
        "      <td> 291</td>\n",
        "      <td> 237</td>\n",
        "      <td> 120</td>\n",
        "      <td> 80</td>\n",
        "      <td> 63</td>\n",
        "      <td> 51</td>\n",
        "      <td> 190</td>\n",
        "      <td>...</td>\n",
        "      <td> 56.53495</td>\n",
        "      <td>   43.769</td>\n",
        "      <td> 10.94225</td>\n",
        "      <td> 15.80547</td>\n",
        "      <td> 25.53191</td>\n",
        "      <td> 27.96353</td>\n",
        "      <td> 16.41337</td>\n",
        "      <td>  22.4924</td>\n",
        "      <td> 24.31611</td>\n",
        "      <td> 11.55015</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>06001409700</th>\n",
        "      <td> 5009</td>\n",
        "      <td> 2436</td>\n",
        "      <td> 181</td>\n",
        "      <td> 323</td>\n",
        "      <td> 289</td>\n",
        "      <td> 129</td>\n",
        "      <td> 48</td>\n",
        "      <td>  0</td>\n",
        "      <td> 72</td>\n",
        "      <td>  63</td>\n",
        "      <td>...</td>\n",
        "      <td> 63.82979</td>\n",
        "      <td> 31.00304</td>\n",
        "      <td> 12.76596</td>\n",
        "      <td> 10.33435</td>\n",
        "      <td> 18.84498</td>\n",
        "      <td> 15.19757</td>\n",
        "      <td> 20.66869</td>\n",
        "      <td> 17.62918</td>\n",
        "      <td> 3.647416</td>\n",
        "      <td> 17.02128</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 98 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 252,
       "text": [
        "            B01001_001E Total: B01001_002E Male:  \\\n",
        "06001409300               5641              2602   \n",
        "06001409400               4661              2405   \n",
        "06001409500               4061              2034   \n",
        "06001409600               5602              2811   \n",
        "06001409700               5009              2436   \n",
        "\n",
        "            B01001_003E Male:!!Under 5 years B01001_004E Male:!!5 to 9 years  \\\n",
        "06001409300                              293                             105   \n",
        "06001409400                              340                             281   \n",
        "06001409500                              261                             156   \n",
        "06001409600                              468                             291   \n",
        "06001409700                              181                             323   \n",
        "\n",
        "            B01001_005E Male:!!10 to 14 years  \\\n",
        "06001409300                               312   \n",
        "06001409400                                90   \n",
        "06001409500                                90   \n",
        "06001409600                               237   \n",
        "06001409700                               289   \n",
        "\n",
        "            B01001_006E Male:!!15 to 17 years  \\\n",
        "06001409300                               139   \n",
        "06001409400                                63   \n",
        "06001409500                                99   \n",
        "06001409600                               120   \n",
        "06001409700                               129   \n",
        "\n",
        "            B01001_007E Male:!!18 and 19 years B01001_008E Male:!!20 years  \\\n",
        "06001409300                                 87                          52   \n",
        "06001409400                                 90                           2   \n",
        "06001409500                                 63                          66   \n",
        "06001409600                                 80                          63   \n",
        "06001409700                                 48                           0   \n",
        "\n",
        "            B01001_009E Male:!!21 years B01001_010E Male:!!22 to 24 years  \\\n",
        "06001409300                          51                                87   \n",
        "06001409400                          54                               277   \n",
        "06001409500                          59                                87   \n",
        "06001409600                          51                               190   \n",
        "06001409700                          72                                63   \n",
        "\n",
        "                           ...                 \\\n",
        "06001409300                ...                  \n",
        "06001409400                ...                  \n",
        "06001409500                ...                  \n",
        "06001409600                ...                  \n",
        "06001409700                ...                  \n",
        "\n",
        "            B01001_040M Standard Error For!!Female:!!50 to 54 years  \\\n",
        "06001409300                                           54.10334        \n",
        "06001409400                                           33.43465        \n",
        "06001409500                                           23.70821        \n",
        "06001409600                                           56.53495        \n",
        "06001409700                                           63.82979        \n",
        "\n",
        "            B01001_041M Standard Error For!!Female:!!55 to 59 years  \\\n",
        "06001409300                                           49.84802        \n",
        "06001409400                                           33.43465        \n",
        "06001409500                                           29.78723        \n",
        "06001409600                                             43.769        \n",
        "06001409700                                           31.00304        \n",
        "\n",
        "            B01001_042M Standard Error For!!Female:!!60 and 61 years  \\\n",
        "06001409300                                            21.2766         \n",
        "06001409400                                           25.53191         \n",
        "06001409500                                           24.31611         \n",
        "06001409600                                           10.94225         \n",
        "06001409700                                           12.76596         \n",
        "\n",
        "            B01001_043M Standard Error For!!Female:!!62 to 64 years  \\\n",
        "06001409300                                           39.51368        \n",
        "06001409400                                           5.471125        \n",
        "06001409500                                           27.96353        \n",
        "06001409600                                           15.80547        \n",
        "06001409700                                           10.33435        \n",
        "\n",
        "            B01001_044M Standard Error For!!Female:!!65 and 66 years  \\\n",
        "06001409300                                           15.19757         \n",
        "06001409400                                           18.23708         \n",
        "06001409500                                            23.1003         \n",
        "06001409600                                           25.53191         \n",
        "06001409700                                           18.84498         \n",
        "\n",
        "            B01001_045M Standard Error For!!Female:!!67 to 69 years  \\\n",
        "06001409300                                           51.06383        \n",
        "06001409400                                           13.98176        \n",
        "06001409500                                           26.74772        \n",
        "06001409600                                           27.96353        \n",
        "06001409700                                           15.19757        \n",
        "\n",
        "            B01001_046M Standard Error For!!Female:!!70 to 74 years  \\\n",
        "06001409300                                           54.10334        \n",
        "06001409400                                           9.118541        \n",
        "06001409500                                           7.902736        \n",
        "06001409600                                           16.41337        \n",
        "06001409700                                           20.66869        \n",
        "\n",
        "            B01001_047M Standard Error For!!Female:!!75 to 79 years  \\\n",
        "06001409300                                           35.86626        \n",
        "06001409400                                           24.31611        \n",
        "06001409500                                           9.726444        \n",
        "06001409600                                            22.4924        \n",
        "06001409700                                           17.62918        \n",
        "\n",
        "            B01001_048M Standard Error For!!Female:!!80 to 84 years  \\\n",
        "06001409300                                           25.53191        \n",
        "06001409400                                           7.902736        \n",
        "06001409500                                           4.863222        \n",
        "06001409600                                           24.31611        \n",
        "06001409700                                           3.647416        \n",
        "\n",
        "            B01001_049M Standard Error For!!Female:!!85 years and over  \n",
        "06001409300                                           30.39514          \n",
        "06001409400                                           15.80547          \n",
        "06001409500                                           16.41337          \n",
        "06001409600                                           11.55015          \n",
        "06001409700                                           17.02128          \n",
        "\n",
        "[5 rows x 98 columns]"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transit2000SF3Tracts = census_api_pull([\"P030001\", \"P030005\"], \"2000\", \"sf3\", \"tract\")\n",
      "transit2000SF3Places = census_api_pull([\"P030001\", \"P030005\"], \"2000\", \"sf3\", \"place\")\n",
      "transit2012ACSTracts = census_api_pull([\"B08301_001E\", \"B08301_001M\", \"B08301_010E\", \"B08301_010M\"], \"2012\", \"acs5\", \"tract\")\n",
      "transit2012ACSPlaces = census_api_pull([\"B08301_001E\", \"B08301_001M\", \"B08301_010E\", \"B08301_010M\"], \"2012\", \"acs5\", \"place\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing data to census_sf3_2000_tract.csv\n",
        "writing data to census_sf3_2000_place.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "writing data to census_acs5_2012_tract.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "writing data to census_acs5_2012_place.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transit_2012_ACS_Elmhurst = transit2012ACSTracts[transit2012ACSTracts.index.isin(elmhurst)]\n",
      "transit_2000_SF3_Elmhurst = transit2000SF3Tracts[transit2000SF3Tracts.index.isin(elmhurst)]\n",
      "transit_2012_ACS_Oakland = transit2012ACSPlaces[transit2012ACSPlaces.index.isin(oakland)]\n",
      "transit_2000_SF3_Oakland = transit2000SF3Places[transit2000SF3Places.index.isin(oakland)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    }
   ],
   "metadata": {}
  }
 ]
}